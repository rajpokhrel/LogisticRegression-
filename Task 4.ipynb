{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize Values\n",
      "Accuracy Score:  0.899970865300573\n",
      "Recall: 0.8840658429459656\n",
      "F1-Score: 0.8903021794119668\n",
      "Precision: 0.8983273622430155\n",
      "[1. 1. 0. ... 0. 0. 1.]\n",
      "[[6162  371]\n",
      " [ 659 3105]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.94      0.92      6533\n",
      "        1.0       0.89      0.82      0.86      3764\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10297\n",
      "\n",
      "Normalize Values\n",
      "Accuracy Score:  0.8986112459939788\n",
      "Recall: 0.8646965397247859\n",
      "F1-Score: 0.8835327182801903\n",
      "Precision: 0.9224638044987566\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[[6479   69]\n",
      " [ 975 2774]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.99      0.93      6548\n",
      "        1.0       0.98      0.74      0.84      3749\n",
      "\n",
      "avg / total       0.91      0.90      0.89     10297\n",
      "\n",
      "Normalize Values\n",
      "Accuracy Score:  0.8538409245411285\n",
      "Recall: 0.8310735421246225\n",
      "F1-Score: 0.8385169323189181\n",
      "Precision: 0.849320972082072\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[[5982  550]\n",
      " [ 955 2810]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.92      0.89      6532\n",
      "        1.0       0.84      0.75      0.79      3765\n",
      "\n",
      "avg / total       0.85      0.85      0.85     10297\n",
      "\n",
      "Normalize Values\n",
      "Accuracy Score:  0.8223754491599495\n",
      "Recall: 0.8273824430493681\n",
      "F1-Score: 0.8149849038996797\n",
      "Precision: 0.8101644420054769\n",
      "[0. 1. 1. ... 1. 1. 1.]\n",
      "[[5263 1247]\n",
      " [ 582 3205]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.81      0.85      6510\n",
      "        1.0       0.72      0.85      0.78      3787\n",
      "\n",
      "avg / total       0.83      0.82      0.82     10297\n",
      "\n",
      "Normalize Values\n",
      "Accuracy Score:  0.881227542002525\n",
      "Recall: 0.8381418740074114\n",
      "F1-Score: 0.8605631054530274\n",
      "Precision: 0.9210152415396539\n",
      "[1. 1. 1. ... 0. 0. 1.]\n",
      "[[6519    0]\n",
      " [1223 2555]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      1.00      0.91      6519\n",
      "        1.0       1.00      0.68      0.81      3778\n",
      "\n",
      "avg / total       0.90      0.88      0.87     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_validation import cross_val_score \n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, confusion_matrix, precision_recall_curve\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "dataArray = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "with open('data/bank-additional-full.csv') as bankFile:\n",
    "    bankReader = csv.reader(bankFile, delimiter=';')\n",
    "    next(bankReader)\n",
    "    for row in bankReader:\n",
    "          for i in range(21):\n",
    "                dataArray[i].append(row[i])\n",
    "\n",
    "dataK1 = pickle.load(open(\"data/feature_selection/feature_k=1.pkl\",'rb'))\n",
    "dataK3 = pickle.load(open(\"data/feature_selection/feature_k=3.pkl\",'rb'))\n",
    "dataK5 = pickle.load(open(\"data/feature_selection/feature_k=5.pkl\",'rb'))\n",
    "\n",
    "\n",
    "Num1 = dataK1['numerical']\n",
    "Cat1 = dataK1['categorical']\n",
    "Num3 = dataK3['numerical']\n",
    "Cat3 = dataK3['categorical']\n",
    "Num5 = dataK5['numerical']\n",
    "Cat5 = dataK5['categorical']\n",
    "\n",
    "Xc = dataK3['categorical'][:,:11]\n",
    "Xn = dataK5['numerical'][:,:5]\n",
    "X = np.concatenate((Xc,Xn),axis=1)\n",
    "\n",
    "X1 = np.concatenate((Num1,Cat1),axis=1)\n",
    "X3 = np.concatenate((Num3,Cat3),axis=1)\n",
    "X5 = np.concatenate((Num5,Cat5),axis=1)\n",
    "y = []\n",
    "\n",
    "for i in range(41188):\n",
    "    y.append(dataK3['categorical'][i][12])\n",
    "\n",
    "#Convert list to np array\n",
    "y = np.asarray(y)\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state= 42)\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(15,15,15),max_iter=500)\n",
    "    mlp.fit(X, y)      \n",
    "    predictions = mlp.predict(X_test)\n",
    "    accur = accuracy_score(y_true=y_test, y_pred=predictions, normalize=True, sample_weight=None)\n",
    "    f1score = f1_score(y_test, predictions, average='macro') \n",
    "    recall = recall_score(y_test, predictions, average='macro')  \n",
    "    precision = precision_score(y_test, predictions, average='macro')  \n",
    "\n",
    "    print(\"Normalize Values\")\n",
    "    print('Accuracy Score: ',accur)\n",
    "    print('Recall:', recall)\n",
    "    print('F1-Score:', f1score)\n",
    "    print('Precision:', precision)\n",
    "    print(predictions)\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.989414392541517\n",
      "Recall: 0.9859182229248442\n",
      "F1-Score: 0.9886378040307104\n",
      "Precision: 0.9916198381877603\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[[6440    1]\n",
      " [ 108 3748]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6441\n",
      "        1.0       1.00      0.97      0.99      3856\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10297\n",
      "\n",
      "Accuracy Score:  0.989414392541517\n",
      "Recall: 0.9859182229248442\n",
      "F1-Score: 0.9886378040307104\n",
      "Precision: 0.9916198381877603\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[[6440    1]\n",
      " [ 108 3748]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6441\n",
      "        1.0       1.00      0.97      0.99      3856\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10297\n",
      "\n",
      "Accuracy Score:  0.989414392541517\n",
      "Recall: 0.9859182229248442\n",
      "F1-Score: 0.9886378040307104\n",
      "Precision: 0.9916198381877603\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[[6440    1]\n",
      " [ 108 3748]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6441\n",
      "        1.0       1.00      0.97      0.99      3856\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10297\n",
      "\n",
      "Accuracy Score:  0.989414392541517\n",
      "Recall: 0.9859182229248442\n",
      "F1-Score: 0.9886378040307104\n",
      "Precision: 0.9916198381877603\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[[6440    1]\n",
      " [ 108 3748]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6441\n",
      "        1.0       1.00      0.97      0.99      3856\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10297\n",
      "\n",
      "Accuracy Score:  0.989414392541517\n",
      "Recall: 0.9859182229248442\n",
      "F1-Score: 0.9886378040307104\n",
      "Precision: 0.9916198381877603\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[[6440    1]\n",
      " [ 108 3748]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6441\n",
      "        1.0       1.00      0.97      0.99      3856\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state= 42)\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    dt = tree.DecisionTreeClassifier(criterion='gini',splitter='best')\n",
    "    dt.fit(X,y)\n",
    "    predictions_d = dt.predict(X_test)\n",
    "    accur_d = accuracy_score(y_true=y_test, y_pred=predictions_d, normalize=True, sample_weight=None)\n",
    "    f1score_d = f1_score(y_test, predictions_d, average='macro')\n",
    "    recall_d = recall_score(y_test, predictions_d, average='macro')\n",
    "    precision_d = precision_score(y_test, predictions_d, average='macro')\n",
    "    print('Accuracy Score: ',accur_d)\n",
    "    print('Recall:', recall_d)\n",
    "    print('F1-Score:', f1score_d)\n",
    "    print('Precision:', precision_d)\n",
    "    print(predictions_d)\n",
    "    print(confusion_matrix(y_test,predictions_d))\n",
    "    print(classification_report(y_test,predictions_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 1. 0. 0.]\n",
      "[[5945  534]\n",
      " [ 539 3279]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.92      0.92      6479\n",
      "        1.0       0.86      0.86      0.86      3818\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10297\n",
      "\n",
      "[1. 0. 1. ... 0. 0. 1.]\n",
      "[[6020  549]\n",
      " [ 532 3196]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.92      0.92      6569\n",
      "        1.0       0.85      0.86      0.86      3728\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10297\n",
      "\n",
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "[[5970  513]\n",
      " [ 592 3222]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.92      0.92      6483\n",
      "        1.0       0.86      0.84      0.85      3814\n",
      "\n",
      "avg / total       0.89      0.89      0.89     10297\n",
      "\n",
      "[0. 1. 1. ... 0. 1. 0.]\n",
      "[[5982  576]\n",
      " [ 563 3176]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.91      0.91      6558\n",
      "        1.0       0.85      0.85      0.85      3739\n",
      "\n",
      "avg / total       0.89      0.89      0.89     10297\n",
      "\n",
      "[0. 1. 0. ... 0. 1. 0.]\n",
      "[[5873  568]\n",
      " [ 557 3299]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.91      0.91      6441\n",
      "        1.0       0.85      0.86      0.85      3856\n",
      "\n",
      "avg / total       0.89      0.89      0.89     10297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "kf = KFold(n_splits = 5, random_state= 42)\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    clf.feature_importances_ \n",
    "    clf.score(X=X_test, y=y_test)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(predictions)\n",
    "    print(confusion_matrix(y_test,predictions))\n",
    "    print(classification_report(y_test,predictions))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 10 and input n_features is 16 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b7dc696f5e1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mpredictions_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0maccur_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mf1score_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \"\"\"\n\u001b[1;32m    411\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    382\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 10 and input n_features is 16 "
     ]
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "xDataArray = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "with open('data/bank-additional-full.csv') as bankFile2:\n",
    "    bankReader2 = csv.reader(bankFile2, delimiter=';')\n",
    "    next(bankReader2)\n",
    "    for row in bankReader2:\n",
    "        xDataArray[0].append(row[0])\n",
    "        xDataArray[1].append(row[1])\n",
    "        xDataArray[2].append(row[2])\n",
    "        xDataArray[3].append(row[3])\n",
    "        xDataArray[4].append(row[4])\n",
    "        xDataArray[5].append(row[5])\n",
    "        xDataArray[6].append(row[6])\n",
    "        xDataArray[7].append(row[7])\n",
    "        xDataArray[8].append(row[8])\n",
    "        xDataArray[9].append(row[9])\n",
    "        xDataArray[10].append(row[10])\n",
    "        xDataArray[11].append(row[11])\n",
    "        xDataArray[12].append(row[12])\n",
    "        xDataArray[13].append(row[13])\n",
    "        xDataArray[14].append(row[14])\n",
    "        xDataArray[15].append(row[15])\n",
    "        xDataArray[16].append(row[16])\n",
    "        xDataArray[17].append(row[17])\n",
    "        xDataArray[18].append(row[18])\n",
    "        xDataArray[19].append(row[19])\n",
    "        xDataArray[20].append(row[20])\n",
    "        \n",
    "df = pd.DataFrame({'age': xDataArray[0],\n",
    "                    'job': xDataArray[1],\n",
    "                    'marital': xDataArray[2],\n",
    "                    'edcation':xDataArray[3],\n",
    "                    'default':xDataArray[4],\n",
    "                    'housing':xDataArray[5],\n",
    "                    'loan':xDataArray[6],\n",
    "                    'contact':xDataArray[7],\n",
    "                    'month':xDataArray[8],\n",
    "                    'day_of_week':xDataArray[9], \n",
    "                    'duration': xDataArray[10], \n",
    "                    'campign':xDataArray[11],\n",
    "                    'pdays':xDataArray[12],\n",
    "                    'previous':xDataArray[13],\n",
    "                    'poutcome':xDataArray[14],\n",
    "                    'emp.var.rate':xDataArray[15],\n",
    "                    'cons.price.idx':xDataArray[16],\n",
    "                    'cons.conf.idx':xDataArray[17],\n",
    "                    'euribor3m':xDataArray[18],\n",
    "                    'nr.employed':xDataArray[19],\n",
    "                    'y':xDataArray[20] })\n",
    "\n",
    "\n",
    "df.apply(LabelEncoder().fit_transform)\n",
    "array = df.values\n",
    "\n",
    "#numpy.array(array)\n",
    "X = array[:,0:19]\n",
    "Y = array[:,20]\n",
    "\n",
    "encodeA = LabelEncoder()\n",
    "\n",
    "job_n = encodeA.fit_transform(xDataArray[1])\n",
    "marital_n = encodeA.fit_transform(xDataArray[2])\n",
    "education_n = encodeA.fit_transform(xDataArray[3])\n",
    "default_n = encodeA.fit_transform(xDataArray[4])\n",
    "housing_n = encodeA.fit_transform(xDataArray[5])\n",
    "loan_n = encodeA.fit_transform(xDataArray[6])\n",
    "contact_n = encodeA.fit_transform(xDataArray[7])\n",
    "month_n = encodeA.fit_transform(xDataArray[8])\n",
    "day_n= encodeA.fit_transform(xDataArray[9])\n",
    "poutcome_n = encodeA.fit_transform(xDataArray[14])\n",
    "\n",
    "y = encodeA.fit_transform(xDataArray[20])\n",
    "\n",
    "age_n = np.array(xDataArray[0]).reshape(-1,1)\n",
    "job_n = np.array(job_n).reshape(-1,1)\n",
    "marital_n = np.array(marital_n).reshape(-1,1)\n",
    "education_n = np.array(education_n).reshape(-1,1)\n",
    "default_n = np.array(default_n).reshape(-1,1)\n",
    "housing_n = np.array(housing_n).reshape(-1,1)\n",
    "loan_n = np.array(loan_n).reshape(-1,1)\n",
    "conact_n = np.array(contact_n).reshape(-1,1)\n",
    "month_n = np.array(month_n).reshape(-1,1)\n",
    "day_n = np.array(day_n).reshape(-1,1)\n",
    "duration_n = np.array(xDataArray[10]).reshape(-1,1)\n",
    "campaign_n = np.array(xDataArray[11]).reshape(-1,1)\n",
    "pdays_n = np.array(xDataArray[12]).reshape(-1,1)\n",
    "previous_n = np.array(xDataArray[13]).reshape(-1,1)\n",
    "poutcome_n = np.array(poutcome_n).reshape(-1,1)\n",
    "empVarRate_n = np.array(xDataArray[15]).reshape(-1,1)\n",
    "consPriceIndex_n = np.array(xDataArray[16]).reshape(-1,1)\n",
    "consConfIndex_n = np.array(xDataArray[17]).reshape(-1,1)\n",
    "euribor3m_n = np.array(xDataArray[18]).reshape(-1,1)\n",
    "nrEmployed_n = np.array(xDataArray[19]).reshape(-1,1)\n",
    "\n",
    "outputX = np.concatenate((job_n, marital_n, education_n, default_n, housing_n, loan_n, conact_n, month_n, day_n, poutcome_n), axis=1)\n",
    "outputY = np.concatenate((age_n, campaign_n, pdays_n, previous_n, empVarRate_n, consPriceIndex_n, consConfIndex_n, euribor3m_n, nrEmployed_n),axis=1)\n",
    "\n",
    "kf = KFold(n_splits = 5, random_state= 10)\n",
    "for train_indices, test_indices in kf.split(outputX):\n",
    "    dt = tree.DecisionTreeClassifier(criterion='gini',splitter='best')\n",
    "    dt.fit(outputX,y)\n",
    "    predictions_d = dt.predict(X_test)\n",
    "    accur_d = accuracy_score(y_true=y_test, y_pred=predictions_d, normalize=True, sample_weight=None)\n",
    "    f1score_d = f1_score(y_test, predictions_d, average='macro')\n",
    "    recall_d = recall_score(y_test, predictions_d, average='macro')\n",
    "    precision_d = precision_score(y_test, predictions_d, average='macro')\n",
    "    print('Accuracy Score: ',accur_d)\n",
    "    print('Recall:', recall_d)\n",
    "    print('F1-Score:', f1score_d)\n",
    "    print('Precision:', precision_d)\n",
    "    print(predictions_d)\n",
    "    print(confusion_matrix(y_test,predictions_d))\n",
    "    print(classification_report(y_test,predictions_d))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
